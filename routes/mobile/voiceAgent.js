import { WebSocketServer } from 'ws';
import { createClient, LiveTranscriptionEvents } from '@deepgram/sdk';
import OpenAI from 'openai';
import fetch from 'node-fetch';
import Chat from '../../models/Chat.js';
import VoiceConfig from '../../models/VoiceConfig.js';

// â”€â”€â”€ Validate environment variables â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const deepgramApiKey   = process.env.DEEPGRAM_API_KEY;
const elevenLabsApiKey = process.env.ELEVENLABS_API_KEY;
const openaiApiKey     = process.env.OPENAI_API_KEY;

// Log API key status
console.log('[VoiceAgent] API Keys Status:');
console.log('  Deepgram:',    deepgramApiKey   ? `${deepgramApiKey.substring(0, 4)}...${deepgramApiKey.substring(deepgramApiKey.length - 4)} (length: ${deepgramApiKey.length})` : 'âŒ MISSING');
console.log('  OpenAI:',      openaiApiKey     ? `${openaiApiKey.substring(0, 7)}...${openaiApiKey.substring(openaiApiKey.length - 4)}` : 'âŒ MISSING');
console.log('  ElevenLabs:',  elevenLabsApiKey ? `${elevenLabsApiKey.substring(0, 4)}...${elevenLabsApiKey.substring(elevenLabsApiKey.length - 4)}` : 'âŒ MISSING');

// â”€â”€â”€ Initialize clients â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
let deepgramClient = null;
let openai = null;

if (deepgramApiKey) {
  deepgramClient = createClient(deepgramApiKey);
  console.log('[VoiceAgent] âœ… Deepgram client initialized');
}

if (openaiApiKey) {
  openai = new OpenAI({ apiKey: openaiApiKey });
  console.log('[VoiceAgent] âœ… OpenAI client initialized');
}

// Fallback constants (used only if no VoiceConfig is found in DB)
const FALLBACK_VOICE_ID = process.env.ELEVENLABS_VOICE_ID || 'EXAVITQu4vr4xnSDxMaL';
const FALLBACK_MODEL_ID = 'eleven_turbo_v2_5';
const DEFAULT_PROMPT    = 'Give the answer within two lines.';

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// WebSocket Voice Agent Handler
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
export const handleVoiceAgentWebSocket = (wss) => {
  wss.on('connection', async (ws, req) => {
    console.log('[VoiceAgent] New WebSocket connection');

    // Check API keys
    if (!deepgramApiKey || !openaiApiKey || !elevenLabsApiKey) {
      console.error('[VoiceAgent] Missing API keys, rejecting connection');
      ws.send(JSON.stringify({
        type: 'error',
        message: 'Server configuration error: Missing API keys',
        error: 'MISSING_API_KEYS',
      }));
      ws.close();
      return;
    }

    // â”€â”€â”€ Connection state â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    let deepgramConnection   = null;
    let silenceTimer         = null;
    let accumulatedTranscript = '';
    let isProcessingLLM      = false;
    let chat                 = null;
    let userId               = null;
    let isActive             = false;
    let audioChunkCount      = 0;
    let voiceConfig          = null;   // â† resolved VoiceConfig document

    const SILENCE_THRESHOLD = 2000;

    // â”€â”€â”€ Cleanup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const cleanup = () => {
      console.log('[VoiceAgent] Cleaning up...');

      if (silenceTimer) {
        clearTimeout(silenceTimer);
        silenceTimer = null;
      }

      if (deepgramConnection) {
        try {
          deepgramConnection.finish();
        } catch (err) {
          console.error('[VoiceAgent] Error finishing Deepgram:', err.message);
        }
        deepgramConnection = null;
      }

      isActive       = false;
      audioChunkCount = 0;
      console.log('[VoiceAgent] Cleanup complete');
    };

    // â”€â”€â”€ Stream TTS from ElevenLabs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const streamElevenLabsTTS = async (text, ws) => {
      try {
        console.log('[VoiceAgent] ðŸ”Š Starting ElevenLabs TTS...');

        // Use values from voiceConfig if available, otherwise fall back to defaults
        const voiceId  = voiceConfig?.voiceId || FALLBACK_VOICE_ID;
        const modelId  = voiceConfig?.modelId || FALLBACK_MODEL_ID;
        const settings = voiceConfig?.voiceSettings || {
          stability:         0.5,
          similarity_boost:  0.75,
          style:             0.0,
          use_speaker_boost: true,
        };

        console.log(`[VoiceAgent] TTS voice: ${voiceId}, model: ${modelId}`);

        const url = `https://api.elevenlabs.io/v1/text-to-speech/${voiceId}/stream`;

        const response = await fetch(url, {
          method: 'POST',
          headers: {
            Accept:           'audio/mpeg',
            'Content-Type':   'application/json',
            'xi-api-key':     elevenLabsApiKey,
          },
          body: JSON.stringify({
            text,
            model_id:       modelId,
            voice_settings: settings,
          }),
        });

        if (!response.ok) {
          const errorText = await response.text();
          throw new Error(`ElevenLabs API error: ${response.status} - ${errorText}`);
        }

        console.log('[VoiceAgent] ðŸ“¡ Streaming TTS audio...');

        let chunkCount = 0;
        for await (const chunk of response.body) {
          if (!isActive) {
            console.log('[VoiceAgent] Session stopped, ending TTS');
            break;
          }
          chunkCount++;
          ws.send(JSON.stringify({
            type:       'audio_chunk',
            audio:      chunk.toString('base64'),
            chunkIndex: chunkCount,
          }));
        }

        ws.send(JSON.stringify({
          type:        'audio_complete',
          totalChunks: chunkCount,
        }));

        console.log('[VoiceAgent] âœ… TTS complete:', chunkCount, 'chunks');

      } catch (error) {
        console.error('[VoiceAgent] ElevenLabs TTS error:', error.message);
        ws.send(JSON.stringify({
          type:    'error',
          message: 'Error generating speech',
          error:   error.message,
        }));
      }
    };

    // â”€â”€â”€ Process complete conversation turn â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    const processTurnComplete = async () => {
      if (!accumulatedTranscript.trim() || isProcessingLLM || !isActive) return;

      const userMessage     = accumulatedTranscript.trim();
      accumulatedTranscript = '';
      isProcessingLLM       = true;

      console.log('[VoiceAgent] ðŸ’¬ Processing turn:', userMessage);

      try {
        // Save user message to chat history
        chat.messages.push({ role: 'user', content: userMessage });
        await chat.save();

        ws.send(JSON.stringify({ type: 'user_message', text: userMessage }));

        // â”€â”€ Build OpenAI messages array â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        // Prepend the voice's prompt as a system message
        const systemPrompt = voiceConfig?.prompt || DEFAULT_PROMPT;

        const messages = [
          { role: 'system', content: systemPrompt },
          ...chat.messages.map(msg => ({ role: msg.role, content: msg.content })),
        ];

        console.log('[VoiceAgent] ðŸ¤– Requesting OpenAI response with system prompt:', systemPrompt);

        const completion = await openai.chat.completions.create({
          model:       process.env.OPENAI_MODEL || 'gpt-4o-mini',
          messages,
          temperature: 0.7,
          max_tokens:  500,
        });

        const aiResponse = completion.choices[0].message.content;
        console.log('[VoiceAgent] âœ… OpenAI response received:', aiResponse.substring(0, 100) + '...');

        // Save assistant message
        chat.messages.push({ role: 'assistant', content: aiResponse });
        await chat.save();

        ws.send(JSON.stringify({ type: 'ai_response', text: aiResponse }));

        // Generate and stream speech using the resolved voiceConfig
        await streamElevenLabsTTS(aiResponse, ws);

      } catch (error) {
        console.error('[VoiceAgent] Error processing turn:', error);
        ws.send(JSON.stringify({
          type:    'error',
          message: 'Error processing response',
          error:   error.message,
        }));
      } finally {
        isProcessingLLM = false;
      }
    };

    // â”€â”€â”€ Handle incoming messages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ws.on('message', async (message) => {
      try {
        const data = JSON.parse(message);

        // â”€â”€ START â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if (data.type === 'start') {
          console.log('[VoiceAgent] Start command received:', {
            chatId:    data.chatId,
            userId:    data.userId,
            voiceName: data.voiceName,
          });

          userId   = data.userId;
          isActive = true;

          // â”€â”€ Resolve VoiceConfig from DB â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          const requestedVoice = data.voiceName || 'krishna1';
          voiceConfig = await VoiceConfig.findOne({ name: requestedVoice, isActive: true });

          if (!voiceConfig) {
            console.warn(`[VoiceAgent] âš ï¸ Voice '${requestedVoice}' not found or inactive â€” falling back to defaults`);
            // Continue with null voiceConfig; streamElevenLabsTTS + processTurnComplete handle fallback
          } else {
            console.log(`[VoiceAgent] ðŸŽ™ï¸ Voice resolved: ${voiceConfig.displayName} (${voiceConfig.voiceId})`);
          }

          // â”€â”€ Find or create chat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          if (data.chatId && data.chatId !== 'new') {
            chat = await Chat.findOne({ _id: data.chatId, userId });
          }

          if (!chat) {
            chat = new Chat({
              userId,
              title:    'Voice Agent Chat',
              messages: [],
            });
            await chat.save();
            console.log('[VoiceAgent] Created new chat:', chat._id);
          }

          // â”€â”€ Initialize Deepgram â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          try {
            console.log('[VoiceAgent] Creating Deepgram connection...');

            deepgramConnection = deepgramClient.listen.live({
              model:           'nova-2',
              language:        'en',
              encoding:        'linear16',
              sample_rate:     16000,
              channels:        1,
              interim_results: true,
              utterance_end_ms: 2000,
              vad_events:      true,
              punctuate:       true,
              smart_format:    true,
            });

            // Open
            deepgramConnection.on(LiveTranscriptionEvents.Open, () => {
              console.log('[VoiceAgent] âœ… Deepgram connection opened');

              ws.send(JSON.stringify({
                type:    'deepgram_connected',
                message: 'Speech recognition active',
              }));

              ws.send(JSON.stringify({
                type:      'started',
                chatId:    chat._id,
                voiceName: voiceConfig?.name || requestedVoice,
                message:   'Voice agent started',
              }));
            });

            // Transcript
            deepgramConnection.on(LiveTranscriptionEvents.Transcript, async (data) => {
              const transcript  = data.channel?.alternatives?.[0]?.transcript;
              const isFinal     = data.is_final;
              const speechFinal = data.speech_final;

              if (transcript && transcript.trim()) {
                console.log('[VoiceAgent] ðŸŽ¤ Transcript:', {
                  text:        transcript,
                  isFinal,
                  speechFinal,
                  confidence:  data.channel?.alternatives?.[0]?.confidence,
                });

                ws.send(JSON.stringify({
                  type:    'transcript',
                  text:    transcript,
                  isFinal,
                }));

                if (isFinal) {
                  accumulatedTranscript += (accumulatedTranscript ? ' ' : '') + transcript;

                  if (silenceTimer) clearTimeout(silenceTimer);
                  silenceTimer = setTimeout(async () => {
                    await processTurnComplete();
                  }, SILENCE_THRESHOLD);
                }
              }
            });

            // UtteranceEnd
            deepgramConnection.on(LiveTranscriptionEvents.UtteranceEnd, async () => {
              console.log('[VoiceAgent] ðŸ”š Utterance end detected');
              if (silenceTimer) clearTimeout(silenceTimer);
              await processTurnComplete();
            });

            // Metadata
            deepgramConnection.on(LiveTranscriptionEvents.Metadata, (data) => {
              console.log('[VoiceAgent] ðŸ“Š Metadata:', {
                request_id: data.request_id,
                model_info: data.model_info,
              });
            });

            // Error
            deepgramConnection.on(LiveTranscriptionEvents.Error, (error) => {
              console.error('[VoiceAgent] âŒ Deepgram error:', {
                message: error.message,
                type:    error.type,
              });

              ws.send(JSON.stringify({
                type:    'error',
                message: 'Speech recognition error',
                error:   error.message,
              }));

              cleanup();
            });

            // Close
            deepgramConnection.on(LiveTranscriptionEvents.Close, () => {
              console.log('[VoiceAgent] Deepgram connection closed');
            });

            console.log('[VoiceAgent] Deepgram connection configured and waiting for open event...');

          } catch (error) {
            console.error('[VoiceAgent] Failed to initialize Deepgram:', error);

            ws.send(JSON.stringify({
              type:    'error',
              message: 'Failed to initialize speech recognition',
              error:   error.message,
            }));

            cleanup();
          }

        // â”€â”€ STOP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        } else if (data.type === 'stop') {
          console.log('[VoiceAgent] Stop command received');
          cleanup();
          ws.send(JSON.stringify({ type: 'stopped', message: 'Voice agent stopped' }));

        // â”€â”€ AUDIO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        } else if (data.type === 'audio') {
          if (deepgramConnection && isActive) {
            try {
              const audioBuffer = Buffer.from(data.audio, 'base64');
              deepgramConnection.send(audioBuffer);

              audioChunkCount++;
              if (audioChunkCount % 50 === 0) {
                console.log(`[VoiceAgent] ðŸ“¤ Sent ${audioChunkCount} audio chunks to Deepgram`);
              }
            } catch (error) {
              console.error('[VoiceAgent] Error sending audio to Deepgram:', error.message);
            }
          } else {
            if (!deepgramConnection) console.warn('[VoiceAgent] âš ï¸ Received audio but Deepgram connection is null');
            if (!isActive)          console.warn('[VoiceAgent] âš ï¸ Received audio but session is not active');
          }
        }

      } catch (error) {
        console.error('[VoiceAgent] Error processing message:', error);
        ws.send(JSON.stringify({
          type:    'error',
          message: 'Error processing message',
          error:   error.message,
        }));
      }
    });

    // â”€â”€â”€ Handle disconnect â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ws.on('close', () => {
      console.log('[VoiceAgent] Client disconnected');
      cleanup();
    });

    ws.on('error', (error) => {
      console.error('[VoiceAgent] WebSocket error:', error.message);
      cleanup();
    });
  });
};

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Export setup function
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
export const setupVoiceAgentWebSocket = (server) => {
  const wss = new WebSocketServer({
    server,
    path: '/api/voice/agent',
  });

  handleVoiceAgentWebSocket(wss);

  console.log('[VoiceAgent] âœ… WebSocket server initialized at /api/voice/agent');
  return wss;
};